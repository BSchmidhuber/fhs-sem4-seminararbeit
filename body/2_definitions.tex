\section{Definitions}


\subsection{Clustering}

When it comes to data analysis in the area of unsupervised machine learning, \textcite[1]{VonLuxburg2007} says that "Clustering is one of the most widely used techniques for exploratory data analysis [...]". For this purpose, data is analyzed so that groups with similar behavior can be identified and summarized.

\textcite[]{Bera2019} sum it up with the addition, that "Clustering is a fundamental unsupervised learning problem where one wants to partition a given data-set. In machine learning, clustering is often used for feature generation and enhancement as well. It is thus important to consider the bias and unfairness issues when inspecting the quality of clusters." \autocite[1]{Bera2019}

While \textcite[1]{Ng2001} claim that "Considerable research in machine learning and pattern recognition" focuses on "the task of finding good clusters", \textcite[1]{Nascimento2011} add that "Clustering is an unsupervised technique concerned with the grouping of related objects without taking their class or label into account."

In this paper we will have a closer look on three main \nameref{clustering-algorithms}, namely \nameref{k-center}, \nameref{k-means} and \nameref{spectral-clustering}.

\subsubsection{$k$-Clustering}

There are multiple variations of $k$-clustering, such as $k$-center, $k$-means and $k$-means++, $k$-median, $k$-medoids, etc., but all of these algorithms have one thing in common: they divide an existing, large data set into a certain number ($k$) of smaller subsets.

As  \textcite[]{Chierichetti2018} said, we understand all different types of $k$-clustering as algorithms based on dividing an existing set of points into $k$ subsets. They describe that one has a set $X$ in a $n$-dimensional space, the $k$-clustering $C$ is a partition of $X$ in $k$ disjoint subsets, $C_{1},...,C_{k}$, called Clusters. \autocite[3]{Chierichetti2018}

Because this paper is primarily concerned with fairness, we will have a closer look at the work of \textcite[]{Chierichetti2018} and \textcite[]{Schmidt2018}.

While the work of \textcite[]{Chierichetti2018} has been about fairness constraints for the \nameref{k-center} and the $k$-median algorithms, \textcite[]{Schmidt2018} have focused on fairness constraints for the \nameref{k-means} algorithm.

\subsubsection{Other Clustering Types}

Although there are many different clustering types, like density-based clustering or distribution-based clustering, we focus on one particular algorithm in this paper, which is the \nameref{spectral-clustering}.

\textcite[]{Kleindessner2019} took a closer look at the fairness aspect of \nameref{spectral-clustering} and developed an algorithm that uses fairness constraints.


\subsection{Fairness}

To define fairness in the area of machine learning, \textcite[1]{Kleindessner2019} said, that "a clustering is fair if every demographic group is approximately proportionally represented in each cluster."

Based on an exemplary data set of 20 individuals, where 10 are female and 10 are male, an applied clustering should not distribute the clusters such that all females are in one cluster and all males are in the other cluster, because that would be highly unfair. Rather there should be approximately the same relative distribution of genders within the clusters. So, for example, if one forms 2 clusters, it would be optimally fair if there were 5 men and 5 women in each cluster. If, on the other hand, one forms 10 clusters, there is optimal fairness only if there is one female and one male in each of the clusters.

In contrast, however, one must be careful that the application of fairness constraints does not lead to significantly worse qualitative results. Therefore, a good mixture must be found between good quality of data and relatively high fairness. The term that is used for this is "cost". This means that one does not want fairness at any price, but wants to keep the cost - i.e. the loss of quality in clustering - as low as possible.

Furthermore, \textcite[1]{Feldman2014CertifyingImpact} raise the question of biased algorithms and claim that "unintentional bias" is called "disparate impact, which occurs when a selection process has widely different outcomes for different groups, even as it appears to be neutral." There is a problem of "determining disparate impact", especially "when computers are involved". \autocite[1]{Feldman2014CertifyingImpact}
