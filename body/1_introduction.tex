\section{Introduction}

In the last couple of years the topic "fairness" in the area of machine learning (ML) has become more and more important. While it was a minor issue in the early years of ML, today it is a topic for which there are separate departments in large companies such as Google.

The first paper that focused on this issue was "Fair Clustering Through Fairlets" by \cite{Chierichetti2018}, it subsequently served as a reference for many other papers in this research area.

The main reason why the topic became so important is that ML is now having a huge impact on our daily lives. Whether smart homes, personalized advertisements on the Internet or self-driving cars - artificial intelligence is being used more and more in each of these areas. This also increases the problem that machines are mostly exposed to unbalanced and biased data when "learning". This ethical problem also comes with technical challenges.

\begin{quote}
    ``Many important decisions today are made by machine learning algorithms. [...] It is important to ensure that such algorithms are fair and are not biased towards or against some specific groups in the population.``
    
\autocite[1]{Bera2019}
\end{quote}


In this paper I want to explain the basics of fairness constraints in ML and compare some of them that can be used in different clustering algorithms in the unsupervised learning \autocite[]{Barlow1989} field, such as spectral clustering \autocite[]{Kleindessner2019}.
